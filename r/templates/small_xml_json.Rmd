---
title: "XML/JSON Analysis Template"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: default
  html_document:
    css: css/custom.css
---

```{r cache=FALSE, echo=FALSE}
# Parameters
# Use this chunk to set the parameters for a test run. 
selection <- 3
export.images <- TRUE
image.folder <- file.path("..","reports","plots","idfor")

use.cases <- c("ais1", "gpx", "owm")
use.case.titles <- c("__Automated Identification System (AIS)__",
                     "__Global Positioning System XML (GPX)__",
                     "__OpenWeatherMap__")
use.case <- use.cases[selection]
use.case.title <- use.case.titles[selection]

library(knitr)
library(ggplot2)
library(reshape2)
library(scales)
library(plyr)
library(grid)

input.file <- file.path("..", "..", "data", paste0(use.case, "_results.csv"))
df <- read.csv(input.file)

source("../utilities/util.R")

opts_chunk$set(fig.width=8, fig.height=4) # Quick adjustment for landscape figures - only affects knitr output
options(warn = -1) # Prevent ggplot2 from dumping warnings to knitr output

counter <- 1 # controls what letter is assigned to a focus question, as well as the letter appended to plot export filenames
```

# Results for `r use.case.title`  Use Case

`r LETTERS[counter]`. Is JSON more compact than XML either when both are plaintext encoded or when both are compressed with conventional compression algorithms?

```{r, echo=FALSE}
s <- c("json",
       "json.gz",
       "json.bz2",
       "xml.gz",
       "xml.bz2")
p <- filesize.vs.compaction(df=df, baseline="xml", series=s, x.range="log")
p <- prettify.plot(p, legend.placement="bottom.left")
print(p)

if(export.images){ save.for.print(image.folder, use.case, paste0("plot-",letters[counter])) }
counter <- counter + 1
```

$\pagebreak$

`r LETTERS[counter]`. Does post-compression with conventional algorithms increase the compactness of BSON or CBOR?

```{r, echo=FALSE}
s <- c("json.bson",
       "json.bson.gz",
       "json.bson.bz2",
       "json.cbor",
       "json.cbor.gz",
       "json.cbor.bz2")
p <- filesize.vs.compaction(df=df, baseline="json", series=s, x.range="log")
p <- prettify.plot(p, legend.placement="bottom.left")
print(p)

if(export.images){ save.for.print(image.folder, use.case, paste0("plot-",letters[counter])) }
counter <- counter + 1
```

$\pagebreak$


`r LETTERS[counter]`. How do the primary EXI modes compare for schemaless and schema-informed encodings?

```{r, echo=FALSE}
s <- c("xml.bitpacked_exi",
       "xml.schema_bitpacked_exi",
       "xml.compress_exi",
       "xml.schema_compress_exi")
p <- filesize.vs.compaction(df=df, baseline="xml", series=s, x.range="log")
p <- prettify.plot(p, legend.placement="top.right")
print(p)

if(export.images){ save.for.print(image.folder, use.case, paste0("plot-",letters[counter])) }
counter <- counter + 1
```

$\pagebreak$


`r LETTERS[counter]`. Is Bitpacked-mode EXI more compact than BSON or CBOR?

```{r, echo=FALSE}
s <- c("xml.bitpacked_exi",
       "xml.schema_bitpacked_exi",
       "xml.strict_bitpacked_exi",
       "json.cbor",
       "json.bson")
p <- filesize.vs.compaction(df=df, baseline="xml", series=s, x.range="log")
p <- prettify.plot(p, legend.placement="mid.right")
print(p)

if(export.images){ save.for.print(image.folder, use.case, paste0("plot-",letters[counter])) }
counter <- counter + 1
```

$\pagebreak$

`r LETTERS[counter]`. Is Compress-mode EXI more compact than BSON or CBOR post-compressed with conventional compression algorithms?

```{r, echo=FALSE}
s <- c("xml.compress_exi",
       "xml.schema_compress_exi",
       "xml.strict_compress_exi",
       "json.cbor.gz",
       "json.bson.gz")
p <- filesize.vs.compaction(df=df, baseline="xml", series=s, x.range="log")
p <- prettify.plot(p, legend.placement="top.right")
print(p)

if(export.images){ save.for.print(image.folder, use.case, paste0("plot-",letters[counter])) }
counter <- counter + 1
```

$\pagebreak$

`r LETTERS[counter]`. For a network already using Gzip compression, do any of the tested binary encodings offer better compactness?

```{r, echo=FALSE}
s <- c("xml.strict_compress_exi",
       "xml.strict_bitpacked_exi",
       "xml.compress_exi",
       "json.gz",
       "json.cbor.gz",
       "json.bson.gz")
p <- filesize.vs.compaction(df=df, baseline="xml.gz", series=s, x.range="log")
p <- prettify.plot(p, legend.placement="bottom.right")
print(p)

if(export.images){ save.for.print(image.folder, use.case, paste0("plot-",letters[counter])) }
counter <- counter + 1
```

<!---------------------------------------------------->
<!-- Unecessary plots. Perhaps move to an appendix. -->
<!---------------------------------------------------->

<!-- ## Extra Plots

`r LETTERS[counter]`. Which binary encoding of JSON is most compact? 

```{r, echo=FALSE}
# s <- c("json.bson",
#        "json.cbor")
# p <- filesize.vs.compaction(df=df, baseline="json", series=s, x.range="log")
# p <- prettify.plot(p, legend.placement="bottom.left")
# print(p)
# 
# if(export.images){ save.for.print(image.folder, use.case, paste0("plot-",letters[counter])) }
# counter <- counter + 1
```

`r LETTERS[counter]`. Does the ‘strict’ option significantly improve compaction for schema-informed encodings?

```{r, echo=FALSE}
# s <- c("xml.schema_bitpacked_exi",
#        "xml.strict_bitpacked_exi",
#        "xml.schema_compress_exi",
#        "xml.strict_compress_exi")
# p <- filesize.vs.compaction(df=df, baseline="xml", series=s, x.range="log")
# p <- prettify.plot(p, legend.placement="bottom.left")
# print(p)
# 
# if(export.images){ save.for.print(image.folder, use.case, paste0("plot-",letters[counter])) }
# counter <- counter + 1
```

`r LETTERS[counter]`. Do any of the tested conventional compression algorithms perform better on a schemaless, precompress EXI document than the standard DEFLATE?

```{r, echo=FALSE}
# s <- c("xml.precompress_exi.zip",
#        "xml.precompress_exi.gz",
#        "xml.precompress_exi.bz2")
# p <- filesize.vs.compaction(df=df, baseline="xml.compress_exi", series=s, x.range="log")
# p <- prettify.plot(p, legend.placement="bottom.left")
# print(p)
# 
# if(export.images){ save.for.print(image.folder, use.case, paste0("plot-",letters[counter])) }
# counter <- counter + 1
```

`r LETTERS[counter]`. Do any of the tested conventional compression algorithms perform better on a schema-informed, precompress EXI document than the standard DEFLATE?

```{r, echo=FALSE}
# s <- c("xml.schema_precompress_exi.zip",
#        "xml.schema_precompress_exi.gz",
#        "xml.schema_precompress_exi.bz2")
# p <- filesize.vs.compaction(df=df, baseline="xml.schema_compress_exi", series=s, x.range="log")
# p <- prettify.plot(p, legend.placement="top.right")
# print(p)
# 
# if(export.images){ save.for.print(image.folder, use.case, paste0("plot-",letters[counter])) }
# counter <- counter + 1
```

`r LETTERS[counter]`. Which of the tested binary formats is the most compact??

```{r, echo=FALSE}
s <- c("json.bson.gz",
       "json.cbor.gz",
       "xml.strict_compress_exi",
       "xml.strict_bitpacked_exi")
p <- filesize.vs.compaction(df=df, baseline="xml", series=s, x.range="log")
p <- prettify.plot(p, legend.placement="top.right")
print(p)

if(export.images){ save.for.print(image.folder, use.case, paste0("plot-",letters[counter])) }
counter <- counter + 1
```
-->
